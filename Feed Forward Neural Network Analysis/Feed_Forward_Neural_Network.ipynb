{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6U72_uJpeBY",
        "outputId": "3300be2f-3143-4d85-f069-f367aea7dd8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch 0, Error: 11.345454391796402\n",
            "Fold: 1, Epoch 100, Error: 1.9914886809845538\n",
            "Fold: 1, Epoch 200, Error: 1.975266894878961\n",
            "Fold: 1, Epoch 300, Error: 1.953870401851647\n",
            "Fold: 1, Epoch 400, Error: 1.9314544923283015\n",
            "Fold: 1, Epoch 500, Error: 1.9124372484494467\n",
            "Fold: 1, Epoch 600, Error: 1.8958309319519064\n",
            "Fold: 1, Epoch 700, Error: 2.4139438183550554\n",
            "Fold: 1, Epoch 800, Error: 1.974601008399274\n",
            "Fold: 1, Epoch 900, Error: 1.9548211504854462\n",
            "Fold: 1, MAE: 1.9001439663578374, MSE: 5.807065762692279, RMSE: 2.4097854183914964, R^2: 0.08400166494563199\n",
            "Fold: 2, Epoch 0, Error: 11.625267954307159\n",
            "Fold: 2, Epoch 100, Error: 1.9406791130161987\n",
            "Fold: 2, Epoch 200, Error: 1.9253787193080847\n",
            "Fold: 2, Epoch 300, Error: 1.9051053913683598\n",
            "Fold: 2, Epoch 400, Error: 1.8839431250611731\n",
            "Fold: 2, Epoch 500, Error: 1.8664369614710226\n",
            "Fold: 2, Epoch 600, Error: 1.8540344601645873\n",
            "Fold: 2, Epoch 700, Error: 3.4145224942961496\n",
            "Fold: 2, Epoch 800, Error: 1.879563727387597\n",
            "Fold: 2, Epoch 900, Error: 1.8607291813788502\n",
            "Fold: 2, MAE: 1.912513182129611, MSE: 6.366128341961381, RMSE: 2.5231187728605606, R^2: -0.07584205037849001\n",
            "Fold: 3, Epoch 0, Error: 11.45374024110052\n",
            "Fold: 3, Epoch 100, Error: 1.9728544075255605\n",
            "Fold: 3, Epoch 200, Error: 1.9537107472787543\n",
            "Fold: 3, Epoch 300, Error: 1.9279235400765284\n",
            "Fold: 3, Epoch 400, Error: 1.9008438692665832\n",
            "Fold: 3, Epoch 500, Error: 1.8784531883984603\n",
            "Fold: 3, Epoch 600, Error: 1.8638134262354793\n",
            "Fold: 3, Epoch 700, Error: 3.487935203701175\n",
            "Fold: 3, Epoch 800, Error: 1.929667460077167\n",
            "Fold: 3, Epoch 900, Error: 1.9055127758939094\n",
            "Fold: 3, MAE: 1.9242963877611339, MSE: 6.654989537202661, RMSE: 2.5797266400149184, R^2: 0.023164777599538167\n",
            "Fold: 4, Epoch 0, Error: 11.234506117691229\n",
            "Fold: 4, Epoch 100, Error: 1.982876321425677\n",
            "Fold: 4, Epoch 200, Error: 1.9641377236700472\n",
            "Fold: 4, Epoch 300, Error: 1.9396363530493854\n",
            "Fold: 4, Epoch 400, Error: 1.9141697420125185\n",
            "Fold: 4, Epoch 500, Error: 1.8946057483401502\n",
            "Fold: 4, Epoch 600, Error: 1.8812295190654786\n",
            "Fold: 4, Epoch 700, Error: 4.1393533650400105\n",
            "Fold: 4, Epoch 800, Error: 1.9076151569636246\n",
            "Fold: 4, Epoch 900, Error: 1.8836779090591047\n",
            "Fold: 4, MAE: 1.9483854409566066, MSE: 5.914737645456972, RMSE: 2.4320233644965197, R^2: 0.07574471400741245\n",
            "Fold: 5, Epoch 0, Error: 11.205587072690339\n",
            "Fold: 5, Epoch 100, Error: 2.006649657401111\n",
            "Fold: 5, Epoch 200, Error: 1.9879063141111617\n",
            "Fold: 5, Epoch 300, Error: 1.9617805408836488\n",
            "Fold: 5, Epoch 400, Error: 1.9334269701533044\n",
            "Fold: 5, Epoch 500, Error: 1.9097095504577706\n",
            "Fold: 5, Epoch 600, Error: 1.8943621875669507\n",
            "Fold: 5, Epoch 700, Error: 1.9768474993466154\n",
            "Fold: 5, Epoch 800, Error: 1.9360972108015004\n",
            "Fold: 5, Epoch 900, Error: 1.9071997151237807\n",
            "Fold: 5, MAE: 1.932954746648805, MSE: 5.621511350500699, RMSE: 2.3709726591634706, R^2: -0.0328018155923\n",
            "Average MAE: 1.923658744770799, Average MSE: 6.072886527562798, Average RMSE: 2.463125370985393, Average R^2: 0.01485345811635852\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset using Pandas\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Spotify_Youtube.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Filter rows with valid 'Likes' and feature column values (exclude rows with missing or non-numeric values)\n",
        "data = data.dropna(subset=['Likes', 'Danceability', 'Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms'])\n",
        "\n",
        "# Extract the 'Likes' column as the target variable\n",
        "y = data['Likes']\n",
        "# Apply logarithmic transformation to the target variable\n",
        "y = np.log1p(y)\n",
        "\n",
        "# Extract the features you want to use for regression\n",
        "X = data[['Danceability', 'Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms']]\n",
        "\n",
        "# Standardize the features (z-score normalization)\n",
        "mean_vals = np.mean(X, axis=0)\n",
        "std_devs = np.std(X, axis=0)\n",
        "X_standardized = (X - mean_vals) / std_devs\n",
        "\n",
        "# Number of folds for cross-validation\n",
        "num_folds = 5\n",
        "fold_size = len(data) // num_folds\n",
        "\n",
        "mae_list, mse_list, rmse_list, r2_list = [], [], [], []\n",
        "\n",
        "for fold in range(num_folds):\n",
        "    # Split the dataset into training and testing sets (using different folds for each iteration)\n",
        "    test_start, test_end = fold * fold_size, (fold + 1) * fold_size\n",
        "    test_indices = list(range(test_start, test_end))\n",
        "    train_indices = [i for i in range(len(data)) if i not in test_indices]\n",
        "\n",
        "    X_train, X_test = X_standardized.iloc[train_indices], X_standardized.iloc[test_indices]\n",
        "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "    # Convert Pandas Series to NumPy array and reshape\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    # Define the neural network architecture\n",
        "    input_size = X_train.shape[1]\n",
        "    hidden_size = 64  # Number of units in the hidden layer\n",
        "    output_size = 1  # For regression\n",
        "\n",
        "    # Initialize weights and bias with small random values\n",
        "    np.random.seed(0)\n",
        "    w1 = np.random.rand(input_size, hidden_size) * 0.01\n",
        "    b1 = np.zeros((1, hidden_size))\n",
        "    w2 = np.random.rand(hidden_size, output_size) * 0.01\n",
        "    b2 = np.zeros((1, output_size))\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.0001  # Adjusted learning rate\n",
        "    epochs = 1000\n",
        "\n",
        "    # Gradient clipping threshold\n",
        "    max_gradient_norm = 1.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward propagation\n",
        "        z1 = np.dot(X_train, w1) + b1\n",
        "        a1 = np.maximum(0, z1)  # ReLU activation\n",
        "        z2 = np.dot(a1, w2) + b2\n",
        "        y_pred = z2\n",
        "\n",
        "        # Calculate the mean absolute error\n",
        "        error = np.mean(np.abs(y_pred - y_train))\n",
        "\n",
        "        # Backpropagation\n",
        "        delta2 = y_pred - y_train\n",
        "        dw2 = np.dot(a1.T, delta2)\n",
        "        db2 = np.sum(delta2, axis=0)\n",
        "\n",
        "        # Implement gradient clipping\n",
        "        dw2 = np.clip(dw2, -max_gradient_norm, max_gradient_norm)\n",
        "\n",
        "        # Calculate delta1 using chain rule\n",
        "        delta1 = np.dot(delta2, w2.T) * (a1 > 0)  # ReLU derivative\n",
        "        dw1 = np.dot(X_train.T, delta1)\n",
        "        db1 = np.sum(delta1, axis=0)\n",
        "\n",
        "        # Implement gradient clipping\n",
        "        dw1 = np.clip(dw1, -max_gradient_norm, max_gradient_norm)\n",
        "\n",
        "        # Update weights and biases\n",
        "        w1 -= learning_rate * dw1\n",
        "        b1 -= learning_rate * db1\n",
        "        w2 -= learning_rate * dw2\n",
        "        b2 -= learning_rate * db2\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f'Fold: {fold + 1}, Epoch {epoch}, Error: {error}')\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    z1_test = np.dot(X_test, w1) + b1\n",
        "    a1_test = np.maximum(0, z1_test)  # ReLU activation\n",
        "    z2_test = np.dot(a1_test, w2) + b2\n",
        "    y_test_pred = z2_test.reshape(-1)  # Adjust the shape to 1-dimensional array\n",
        "\n",
        "    # Calculate performance metrics for the fold\n",
        "    mae = np.mean(np.abs(y_test_pred - y_test))  # Mean Absolute Error\n",
        "    mse = np.mean((y_test_pred - y_test) ** 2)     # Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "    ss_res = np.sum((y_test - y_test_pred) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    mae_list.append(mae)\n",
        "    mse_list.append(mse)\n",
        "    rmse_list.append(rmse)\n",
        "    r2_list.append(r2)\n",
        "\n",
        "    # Print or log the metrics for the fold\n",
        "    print(f'Fold: {fold + 1}, MAE: {mae}, MSE: {mse}, RMSE: {rmse}, R^2: {r2}')\n",
        "\n",
        "# After the loop, calculate and print average metrics across all folds\n",
        "print(f'Average MAE: {np.mean(mae_list)}, Average MSE: {np.mean(mse_list)}, Average RMSE: {np.mean(rmse_list)}, Average R^2: {np.mean(r2_list)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMy2a60lxdFZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
